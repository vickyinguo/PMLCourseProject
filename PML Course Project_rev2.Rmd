---
title: "PML Course Project"
author: "Ying Guo"
date: "December 9, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, my goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants and to predict the manner in which they did the exercise from the 5 correct and incorrect different ways they were asked to perform barbell lifts.

## Data Preparation

First read in data:
```{r}
testing <- read.csv("C:/Users/yguo/Documents/R/pml-testing.csv")
training <- read.csv("C:/Users/yguo/Documents/R/pml-training.csv")
```

Get dimension of training and testing set and first few rows of training set:
```{r}
dim(testing)
dim(training)
```

```{r results='hide'}
head(training)
```

There are a lot of NA's and blanks in the data set. Remove the variables that has NA or blank in it, also the first 7 variables since they are not related to how the human acitivity is performed, put in trainingnew and testingnew respectively.
```{r}
trainingnew <- training[, colSums(is.na(training)) == 0]
trainingnew <- trainingnew[, colSums(trainingnew != "") == nrow (trainingnew)]
trainingnew <- trainingnew[,-c(1:7)]
testingnew <- testing[, colSums(is.na(testing)) == 0]
testingnew <- testingnew[, colSums(testingnew != "") == nrow (testingnew)]
testingnew <- testingnew[,-c(1:7)]
```

Get dimension of new training and testing set:
```{r}
dim(testingnew)
dim(trainingnew)
```

Partition training set into real training set for the machine learning models and cross validation set:
```{r results='hide'}
set.seed(125)
library(caret)
inTrain <- createDataPartition(y=trainingnew$classe,p=0.7,list=FALSE)
realtrain <- trainingnew[inTrain,]
cv <- trainingnew[-inTrain,]
```

## Train Models
Train a multilevel logistic model to the realtrain data set:
```{r cache = TRUE, results='hide'}
control <- trainControl(method = "cv", number = 5)
fit <- train(classe ~ ., data = realtrain, method = "multinom", trControl = control)
```

Test on cross validation set and calculate accuracy:
```{r results='hide'}
predict <- predict(fit,cv)
confusionMatrix(predict, cv$classe)
```

Accuracy on cross validation set is only 66%. Not so good.

Train a random forest model to the realtrain data set instead:
```{r cache = TRUE, results='hide'}
fit2 <- train(classe ~ ., data = realtrain, method = "rf", trControl = control)
```

Test on cross validation set and calculate accuracy:
```{r}
predict2 <- predict(fit2,cv)
confusionMatrix(predict2, cv$classe)
```

Accuracy increased to 99%!

## Run on test set
```{r}
predicttesting <- predict(fit2,testingnew)
predicttesting
```

## Conclusion
Random forest model fits the data better. The out of sample error is 1-99.22 = 0.78%.

End
